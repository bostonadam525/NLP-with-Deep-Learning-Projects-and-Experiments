{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Translation Pipeline in Hugging Face\n",
        "* Notebook by Adam Lang\n",
        "* Date: 12/4/2024\n",
        "\n",
        "# Overview\n",
        "* In this notebook I will implement a translation pipeline in hugging face using transformers."
      ],
      "metadata": {
        "id": "PKw_YUCD6Zpo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6by6KakS6UUn",
        "outputId": "fab8181b-534d-49f8-a668-b4741abeae36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.2\n",
            "    Uninstalling transformers-4.46.2:\n",
            "      Successfully uninstalled transformers-4.46.2\n",
            "Successfully installed transformers-4.46.3\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2024.9.11)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.6)\n",
            "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n"
          ]
        }
      ],
      "source": [
        "## install dependencies\n",
        "!pip install -U transformers #upgrades\n",
        "!pip install -U sentencepiece #upgrades\n",
        "!pip install -U sacremoses #upgrades"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## imports - transformers\n",
        "from transformers import pipeline\n",
        "from transformers import set_seed\n",
        "set_seed(42) #set seed for consistency\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Bm4xYsGG6sQR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation Pipeline\n",
        "* We will demo how to implement a translation pipeline.\n",
        "* If we don't set the model name then it defaults to: `google-t5/t5-base and revision a9723ea`\n",
        "  * model card: https://huggingface.co/google-t5/t5-base"
      ],
      "metadata": {
        "id": "ZyBCcu9A64Ay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## text to translate\n",
        "text = \"\"\"\n",
        "Dear Amazon, last week I ordered a new pair of alpine skis\n",
        "from your online store in Seattle. Unfortunately when I opened\n",
        "the package, I discovered that I had accidentally been sent a Snowboard instead!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8-e2EoiV77mm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## setup translator pipeline -- english to german\n",
        "translator = pipeline(\"translation_en_to_de\")\n",
        "\n",
        "# set outputs\n",
        "outputs = translator(text)\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO6qgrwF63S3",
        "outputId": "985387f7-2e6a-4e7f-bb25-baa55e40e333"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Dear Amazon, last week I ordered a new pair of alpine skis from your online store in Seattle, unfortunately when I opened the package, I discovered that I had accidentally been sent a Snowboard instead!'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "* However, we can see that the T5-base model did not actually translate the text from english to german.\n",
        "* So, we need to set the model name with a specific model that translates english to german."
      ],
      "metadata": {
        "id": "6hCIwC4Q8J2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using a specific Translation Model: English to German\n",
        "* We will use a model from the Helsinki family of models which I have actually used quite a bit before.\n",
        "* The specific model is: `Helsinki-NLP/opus-mt-en-de`\n",
        "  * model card: https://huggingface.co/Helsinki-NLP/opus-mt-en-de"
      ],
      "metadata": {
        "id": "3Wx9j9JH8vP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## setup translator pipeline -- english to german\n",
        "translator = pipeline(\"translation_en_to_de\",\n",
        "                      model=\"Helsinki-NLP/opus-mt-en-de\")\n",
        "\n",
        "# set outputs\n",
        "from IPython.display import Markdown\n",
        "\n",
        "outputs = translator(text)\n",
        "#outputs\n",
        "## output to markdown\n",
        "Markdown(outputs[0][\"translation_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "Y0uoAUf07LD-",
        "outputId": "46ceeaee-18c6-4cdd-bb3d-92bc3942e54b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Liebe Amazon, letzte Woche habe ich ein neues Paar Alpinski in Ihrem Online-Shop in Seattle bestellt. Leider habe ich beim Öffnen des Pakets entdeckt, dass ich versehentlich ein Snowboard geschickt worden war!"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}